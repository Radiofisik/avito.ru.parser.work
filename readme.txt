4.09.2015

Оригинальное задание - http://freelansim.ru/tasks/121215
----------------------------------------------------------
Парсер статей на Python 2.7

Парсер контента (статей) с http://ezinearticles.com/

Парсер берет из списка кейворд
Делает http://ezinearticles.com/search/?q=some+query
Парсит все статьи из выдачи
Разделяет результат на отдельные предложения
Пушит результат в базу

lxml, requests, scrapy - ок. 

Написание на малоизвестных либах не допускается.

----------------------------------------------------------

7.09.2015

Начиналось все с "Парсер статей на Python 2.7", а закончилось все учебным заданием для Авито. Авито, потому что надеюсь не фильтрует по количеству запросов в еденицу времени, как это делает http://ezinearticles.com/.
Парсер обрабатывает раздел "Работа", регион "Санкт-Петербург", фильтрует данные "Вакансии", "Зарплата", "Тип" и записывает данные в файл, в "csv" формате.


----------------------------------------------------------
10.09.2015

Переименовал корневую папку и создал git репозитарий.
Пояснение, почему много файлов parser1 - parser6: проект начинался без git, и это своеобразная система версий.
parser1.py - пример рабочего парсера.
Видео пособие - https://www.youtube.com/watch?v=KPXPr-KS-qk. Название - "Python 3. Практика. Пишем парсер web-caйта." Код - https://gist.github.com/mr-linch/ea6803f8df5d3805464a.
Скрпит написан на python 2.7. Такое было техническое задание.
----------------------------------------------------------



Монтируем удаленную папку

sshfs -p ... dp@....:/home/dp/project/ ~/Sport.cap.ru

Размонтируем удаленную папку

fusermount -u ~/Sport.cap.ru
----------------------------------------------------------

